{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from functools import reduce\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPComplete.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local libraries\n",
    "sys.path.append('../')\n",
    "from down.lib.automata import automata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(n):\n",
    "    assert n<=7\n",
    "    assert n>=0\n",
    "\n",
    "    arr = np.zeros(3)\n",
    "    for i in range(2,-1,-1):\n",
    "        pos_val = 2**(i)\n",
    "        if n >= pos_val:\n",
    "            arr[i]=1\n",
    "            n-=pos_val\n",
    "    return arr\n",
    "\n",
    "def filters(rule_number):\n",
    "    filters = []\n",
    "    inc = \"{0:b}\".format(rule_number)[::-1]\n",
    "    for i,v in enumerate(inc):\n",
    "        if v=='1':\n",
    "            filters.append(filter(i))\n",
    "    return filters\n",
    "\n",
    "def apply_filter(state, f):\n",
    "    vf = np.vectorize(lambda x: 1 if x==f.sum() else 0)\n",
    "    return vf(np.convolve(state, f, mode='same'))\n",
    "\n",
    "def apply_filters(state, fs):\n",
    "    res = np.array([apply_filter(state, f) for f in fs])\n",
    "    res = np.sum(res,axis=0)\n",
    "    return (res%2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_init_state(n):\n",
    "    state = np.zeros(n,dtype=int)\n",
    "    state[n//2]=1\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE_SET = 90\n",
    "INIT = middle_init_state(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_DENSITY = 100\n",
    "DENSITIES = [.1*x for x in range(2,9)]\n",
    "WIDTH = 61\n",
    "GENERATIONS = 2*WIDTH\n",
    "RULE_SET = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = []\n",
    "for p in DENSITIES:\n",
    "    for _ in range(SAMPLES_PER_DENSITY):\n",
    "        arr = np.random.random_sample(WIDTH) > (1-p)\n",
    "        inits.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [automata.generate_1d(RULE_SET, init, GENERATIONS) for init in inits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x147321710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(1-patterns[400],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patterns_to_x_y(pattern):\n",
    "    ins = []\n",
    "    outs = []\n",
    "    for i in range(pattern.shape[0]-1):\n",
    "        ins.append(pattern[i])\n",
    "        outs.append(pattern[i+1])\n",
    "    return ins, outs\n",
    "\n",
    "def patterns_to_dataset(patterns):\n",
    "    pairs = [patterns_to_x_y(pattern) for pattern in patterns]\n",
    "    x_list, y_list = zip(*pairs)\n",
    "    xx = list(itertools.chain(*x_list))\n",
    "    yy = list(itertools.chain(*y_list))\n",
    "    return xx, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = patterns_to_dataset(patterns)\n",
    "x = np.array(x, dtype=np.float)\n",
    "y = np.array(y,dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = tf.data.Dataset.from_tensor_slices({'x':x, 'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(tf.keras.Model):\n",
    "    def __init__(self, h1, width):\n",
    "        super(BasicModel, self).__init__()\n",
    "        self.h1 = tf.keras.layers.Dense(h1, activation='relu')\n",
    "        self.h2 = tf.keras.layers.Dense(width, activation='relu')\n",
    "        self.do1 = tf.keras.layers.Dropout(.2)\n",
    "        \n",
    "    def call(self, x):\n",
    "        o1 = self.do1(self.h1(x))\n",
    "        return self.h2(o1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = BasicModel(125, WIDTH)\n",
    "\n",
    "loss_function = tf.keras.losses.binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.float64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.float64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = basic_model(inp)\n",
    "        loss = loss_function(tar, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, basic_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, basic_model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    #train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model.compile(optimizer, loss_function)\n",
    "#basic_model.fit(x,y,128, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function(np.array([1,3,4]),np.array([5,6,7])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic_model(batch['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0003\n",
      "Epoch 1 Batch 40 Loss 0.0001\n",
      "Epoch 1 Batch 80 Loss 0.0001\n",
      "Epoch 1 Batch 120 Loss 0.0001\n",
      "Epoch 1 Batch 160 Loss 0.0001\n",
      "Epoch 1 Batch 200 Loss 0.0002\n",
      "Epoch 1 Batch 240 Loss 0.0002\n",
      "Epoch 1 Batch 280 Loss 0.0002\n",
      "Epoch 1 Batch 320 Loss 0.0003\n",
      "Epoch 1 Batch 360 Loss 0.0003\n",
      "Epoch 1 Batch 400 Loss 0.0003\n",
      "Epoch 1 Batch 440 Loss 0.0003\n",
      "Epoch 1 Batch 480 Loss 0.0003\n",
      "Epoch 1 Batch 520 Loss 0.0003\n",
      "Epoch 1 Batch 560 Loss 0.0003\n",
      "Epoch 1 Batch 600 Loss 0.0003\n",
      "Epoch 1 Batch 640 Loss 0.0003\n",
      "Epoch 2 Batch 0 Loss 0.0003\n",
      "Epoch 2 Batch 40 Loss 0.0001\n",
      "Epoch 2 Batch 80 Loss 0.0001\n",
      "Epoch 2 Batch 120 Loss 0.0001\n",
      "Epoch 2 Batch 160 Loss 0.0001\n",
      "Epoch 2 Batch 200 Loss 0.0002\n",
      "Epoch 2 Batch 240 Loss 0.0002\n",
      "Epoch 2 Batch 280 Loss 0.0002\n",
      "Epoch 2 Batch 320 Loss 0.0003\n",
      "Epoch 2 Batch 360 Loss 0.0003\n",
      "Epoch 2 Batch 400 Loss 0.0003\n",
      "Epoch 2 Batch 440 Loss 0.0003\n",
      "Epoch 2 Batch 480 Loss 0.0003\n",
      "Epoch 2 Batch 520 Loss 0.0003\n",
      "Epoch 2 Batch 560 Loss 0.0003\n",
      "Epoch 2 Batch 600 Loss 0.0003\n",
      "Epoch 2 Batch 640 Loss 0.0003\n",
      "Epoch 3 Batch 0 Loss 0.0003\n",
      "Epoch 3 Batch 40 Loss 0.0001\n",
      "Epoch 3 Batch 80 Loss 0.0001\n",
      "Epoch 3 Batch 120 Loss 0.0001\n",
      "Epoch 3 Batch 160 Loss 0.0001\n",
      "Epoch 3 Batch 200 Loss 0.0002\n",
      "Epoch 3 Batch 240 Loss 0.0002\n",
      "Epoch 3 Batch 280 Loss 0.0002\n",
      "Epoch 3 Batch 320 Loss 0.0002\n",
      "Epoch 3 Batch 360 Loss 0.0003\n",
      "Epoch 3 Batch 400 Loss 0.0003\n",
      "Epoch 3 Batch 440 Loss 0.0003\n",
      "Epoch 3 Batch 480 Loss 0.0003\n",
      "Epoch 3 Batch 520 Loss 0.0003\n",
      "Epoch 3 Batch 560 Loss 0.0003\n",
      "Epoch 3 Batch 600 Loss 0.0003\n",
      "Epoch 3 Batch 640 Loss 0.0003\n",
      "Epoch 4 Batch 0 Loss 0.0002\n",
      "Epoch 4 Batch 40 Loss 0.0001\n",
      "Epoch 4 Batch 80 Loss 0.0001\n",
      "Epoch 4 Batch 120 Loss 0.0001\n",
      "Epoch 4 Batch 160 Loss 0.0001\n",
      "Epoch 4 Batch 200 Loss 0.0002\n",
      "Epoch 4 Batch 240 Loss 0.0002\n",
      "Epoch 4 Batch 280 Loss 0.0002\n",
      "Epoch 4 Batch 320 Loss 0.0002\n",
      "Epoch 4 Batch 360 Loss 0.0003\n",
      "Epoch 4 Batch 400 Loss 0.0003\n",
      "Epoch 4 Batch 440 Loss 0.0003\n",
      "Epoch 4 Batch 480 Loss 0.0003\n",
      "Epoch 4 Batch 520 Loss 0.0003\n",
      "Epoch 4 Batch 560 Loss 0.0003\n",
      "Epoch 4 Batch 600 Loss 0.0003\n",
      "Epoch 4 Batch 640 Loss 0.0003\n",
      "Epoch 5 Batch 0 Loss 0.0002\n",
      "Epoch 5 Batch 40 Loss 0.0001\n",
      "Epoch 5 Batch 80 Loss 0.0001\n",
      "Epoch 5 Batch 120 Loss 0.0001\n",
      "Epoch 5 Batch 160 Loss 0.0001\n",
      "Epoch 5 Batch 200 Loss 0.0002\n",
      "Epoch 5 Batch 240 Loss 0.0002\n",
      "Epoch 5 Batch 280 Loss 0.0002\n",
      "Epoch 5 Batch 320 Loss 0.0002\n",
      "Epoch 5 Batch 360 Loss 0.0002\n",
      "Epoch 5 Batch 400 Loss 0.0003\n",
      "Epoch 5 Batch 440 Loss 0.0003\n",
      "Epoch 5 Batch 480 Loss 0.0003\n",
      "Epoch 5 Batch 520 Loss 0.0003\n",
      "Epoch 5 Batch 560 Loss 0.0003\n",
      "Epoch 5 Batch 600 Loss 0.0003\n",
      "Epoch 5 Batch 640 Loss 0.0003\n",
      "Epoch 6 Batch 0 Loss 0.0002\n",
      "Epoch 6 Batch 40 Loss 0.0001\n",
      "Epoch 6 Batch 80 Loss 0.0001\n",
      "Epoch 6 Batch 120 Loss 0.0001\n",
      "Epoch 6 Batch 160 Loss 0.0001\n",
      "Epoch 6 Batch 200 Loss 0.0002\n",
      "Epoch 6 Batch 240 Loss 0.0002\n",
      "Epoch 6 Batch 280 Loss 0.0002\n",
      "Epoch 6 Batch 320 Loss 0.0002\n",
      "Epoch 6 Batch 360 Loss 0.0002\n",
      "Epoch 6 Batch 400 Loss 0.0002\n",
      "Epoch 6 Batch 440 Loss 0.0002\n",
      "Epoch 6 Batch 480 Loss 0.0003\n",
      "Epoch 6 Batch 520 Loss 0.0002\n",
      "Epoch 6 Batch 560 Loss 0.0003\n",
      "Epoch 6 Batch 600 Loss 0.0003\n",
      "Epoch 6 Batch 640 Loss 0.0003\n",
      "Epoch 7 Batch 0 Loss 0.0002\n",
      "Epoch 7 Batch 40 Loss 0.0001\n",
      "Epoch 7 Batch 80 Loss 0.0001\n",
      "Epoch 7 Batch 120 Loss 0.0001\n",
      "Epoch 7 Batch 160 Loss 0.0001\n",
      "Epoch 7 Batch 200 Loss 0.0001\n",
      "Epoch 7 Batch 240 Loss 0.0002\n",
      "Epoch 7 Batch 280 Loss 0.0002\n",
      "Epoch 7 Batch 320 Loss 0.0002\n",
      "Epoch 7 Batch 360 Loss 0.0002\n",
      "Epoch 7 Batch 400 Loss 0.0002\n",
      "Epoch 7 Batch 440 Loss 0.0002\n",
      "Epoch 7 Batch 480 Loss 0.0002\n",
      "Epoch 7 Batch 520 Loss 0.0002\n",
      "Epoch 7 Batch 560 Loss 0.0002\n",
      "Epoch 7 Batch 600 Loss 0.0003\n",
      "Epoch 7 Batch 640 Loss 0.0003\n",
      "Epoch 8 Batch 0 Loss 0.0002\n",
      "Epoch 8 Batch 40 Loss 0.0001\n",
      "Epoch 8 Batch 80 Loss 0.0001\n",
      "Epoch 8 Batch 120 Loss 0.0001\n",
      "Epoch 8 Batch 160 Loss 0.0001\n",
      "Epoch 8 Batch 200 Loss 0.0001\n",
      "Epoch 8 Batch 240 Loss 0.0002\n",
      "Epoch 8 Batch 280 Loss 0.0002\n",
      "Epoch 8 Batch 320 Loss 0.0002\n",
      "Epoch 8 Batch 360 Loss 0.0002\n",
      "Epoch 8 Batch 400 Loss 0.0002\n",
      "Epoch 8 Batch 440 Loss 0.0002\n",
      "Epoch 8 Batch 480 Loss 0.0002\n",
      "Epoch 8 Batch 520 Loss 0.0002\n",
      "Epoch 8 Batch 560 Loss 0.0002\n",
      "Epoch 8 Batch 600 Loss 0.0002\n",
      "Epoch 8 Batch 640 Loss 0.0002\n",
      "Epoch 9 Batch 0 Loss 0.0002\n",
      "Epoch 9 Batch 40 Loss 0.0001\n",
      "Epoch 9 Batch 80 Loss 0.0001\n",
      "Epoch 9 Batch 120 Loss 0.0001\n",
      "Epoch 9 Batch 160 Loss 0.0001\n",
      "Epoch 9 Batch 200 Loss 0.0001\n",
      "Epoch 9 Batch 240 Loss 0.0002\n",
      "Epoch 9 Batch 280 Loss 0.0002\n",
      "Epoch 9 Batch 320 Loss 0.0002\n",
      "Epoch 9 Batch 360 Loss 0.0002\n",
      "Epoch 9 Batch 400 Loss 0.0002\n",
      "Epoch 9 Batch 440 Loss 0.0002\n",
      "Epoch 9 Batch 480 Loss 0.0002\n",
      "Epoch 9 Batch 520 Loss 0.0002\n",
      "Epoch 9 Batch 560 Loss 0.0002\n",
      "Epoch 9 Batch 600 Loss 0.0002\n",
      "Epoch 9 Batch 640 Loss 0.0002\n",
      "Epoch 10 Batch 0 Loss 0.0002\n",
      "Epoch 10 Batch 40 Loss 0.0001\n",
      "Epoch 10 Batch 80 Loss 0.0001\n",
      "Epoch 10 Batch 120 Loss 0.0001\n",
      "Epoch 10 Batch 160 Loss 0.0001\n",
      "Epoch 10 Batch 200 Loss 0.0001\n",
      "Epoch 10 Batch 240 Loss 0.0001\n",
      "Epoch 10 Batch 280 Loss 0.0001\n",
      "Epoch 10 Batch 320 Loss 0.0002\n",
      "Epoch 10 Batch 360 Loss 0.0002\n",
      "Epoch 10 Batch 400 Loss 0.0002\n",
      "Epoch 10 Batch 440 Loss 0.0002\n",
      "Epoch 10 Batch 480 Loss 0.0002\n",
      "Epoch 10 Batch 520 Loss 0.0002\n",
      "Epoch 10 Batch 560 Loss 0.0002\n",
      "Epoch 10 Batch 600 Loss 0.0002\n",
      "Epoch 10 Batch 640 Loss 0.0002\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "data = h.batch(128)\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    for batch_num, batch in enumerate(data):\n",
    "        train_step(batch['x'], batch['y'])\n",
    "        if (batch_num%40)==0:\n",
    "            s = 'Epoch {} Batch {} Loss {:.4f}'\n",
    "            print(s.format(epoch + 1, batch_num, train_loss.result()))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = basic_model(x[:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(p[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
